"00060"=c("Instantaneous discharge"), # note this is UV equiv to 00061
"00095"=c("Specific conductivity"),
"00300"=c("Dissolved oxygen"),
"00400"=c("Field pH"))
n.param <- length(params)
get.state.sites <- function(state,n.param){
site.list.all <- list() # site list with all params
for (i in 1:n.param){
# first call state sites for param
state.url <- paste("http://waterservices.usgs.gov/nwis/site/",
"?format=rdb",
"&stateCd=",state,
"&parameterCd=",names(params[i]),
"&hasDataTypeCd=iv",sep='')
cat(state.url)
# need to handle 404 and other errors
site.file <- get.site.data(state.url)
# this gives number of sites in this state
n.sites <- length(site.file$site_no)
site.list.all <- c(site.list.all, paste(site.file$site_no,collapse=','))
site.stop <- NULL
site.end <- NULL
#for (s in 1:n.sites)
#  site
cat(names(params[i]));cat('\n')
}
return(site.list.all)
}
# now find all sites that exist in all parts of the site list
get.site.matches <- function(site.list.all,n.param){
all.sites.dup <- paste(unlist(site.list.all),collapse=',') # all sites with replicates
all.sites.vec <- strsplit(all.sites.dup,',')[[1]]
unique.sites <- unique(all.sites.vec)
n.unique <- length(unique.sites)
use.sites <- vector(length=n.unique)
for (i in 1:n.unique){
if (sum(all.sites.vec==unique.sites[i])==n.param)
use.sites[i] = TRUE
}
return(unique.sites[use.sites])
}
get.site.data <- function(site.url){
siteFile <- read.delim(
site.url,
header = TRUE,
quote="\"",
sep='\t',
colClasses=c('character'),
fill = TRUE,
comment.char="#")
# assumes rdp format, and single row of headers
return(siteFile[-1,]) # get rid of top header
}
getParamStartEndUV <- function(site.id,param){
data.avail <- getDataAvailability(site.id,interactive = FALSE)
param.start <- data.avail[data.avail$service=="uv" &
data.avail$parameter_cd==param,]$startDate
param.end <- data.avail[data.avail$service=="uv" &
data.avail$parameter_cd==param,]$endDate
return(data.frame("start"=param.start,"end"=param.end))
}
getTimeLimit <- function(site.id,param.cd){
# returns the shortest time period where all data overlap. NA if none
# params is character vector
# site.id is a string
stop.time <- "2100-01-01" # supposed to be GREATER than any in NWIS
start.time <- "1700-01-01" # supposed to be LESS than any in NWIS
for (p in 1:length(param.cd)){
# can be 404, can be empty
start.stop.df <- getParamStartEndUV(site.id,param.cd[p])[1,]
# test right, test left
if (as.Date(start.stop.df$start)>as.Date(start.time)){
start.time = start.stop.df$start
}
if (as.Date(start.stop.df$end)<as.Date(stop.time)){
stop.time = start.stop.df$end
}
# if any are empty, break with NA
}
return(data.frame("start"=start.time,'end'=stop.time))
}
state = 'MN'
state.list <- get.state.sites(state,n.param)
state.list <- get.site.matches(state.list,n.param)
time.limit = data.frame(start=NULL, end=NULL)
for (s in 1:length(state.list)){
t.l <- getTimeLimit(site.id=state.list[s],param.cd=names(params))
time.limit = rbind(time.limit,data.frame(start=t.l$start,end=t.l$end))
}
time.limit = cbind(site_id=state.list,time.limit)
#time.limit <- getTimeLimit(site.id,param.cd=names(params))
time.list
time.limit
state = 'MI'
state.list <- get.state.sites(state,n.param)
state.list <- get.site.matches(state.list,n.param)
time.limit = data.frame(start=NULL, end=NULL)
for (s in 1:length(state.list)){
t.l <- getTimeLimit(site.id=state.list[s],param.cd=names(params))
time.limit = rbind(time.limit,data.frame(start=t.l$start,end=t.l$end))
}
time.limit = cbind(site_id=state.list,time.limit)
#time.limit <- getTimeLimit(site.id,param.cd=names(params))
time.limit
setwd("~/Documents/R/rNWIS/R")
state = 'OH'
state.list <- get.state.sites(state,n.param)
state.list <- get.site.matches(state.list,n.param)
time.limit = data.frame(start=NULL, end=NULL)
for (s in 1:length(state.list)){
t.l <- getTimeLimit(site.id=state.list[s],param.cd=names(params))
time.limit = rbind(time.limit,data.frame(start=t.l$start,end=t.l$end))
}
time.limit
time.limit = cbind(site_id=state.list,time.limit)
state = 'OH'
state.list <- get.state.sites(state,n.param)
state.list <- get.site.matches(state.list,n.param)
time.limit = data.frame(start=NULL, end=NULL)
for (s in 1:length(state.list)){
t.l <- getTimeLimit(site.id=state.list[s],param.cd=names(params))
time.limit = rbind(time.limit,data.frame(start=t.l$start,end=t.l$end))
}
time.limit = cbind(site_id=state.list,time.limit)
#time.limit <- getTimeLimit(site.id,param.cd=names(params))
time.limit
source('~/Documents/R/rNWIS/R/getMetabSites.R', echo=TRUE)
source('~/Documents/R/rNWIS/R/getMetabSites.R', echo=TRUE)
source('~/Documents/R/rNWIS/R/getMetabSites.R', echo=TRUE)
state
state.list <- get.state.sites(state,n.param)
state.list <- get.site.matches(state.list,n.param)
state.list
length(state.list)
source('~/Documents/R/rNWIS/R/getMetabSites.R', echo=TRUE)
source('~/Documents/R/rNWIS/R/getMetabSites.R', echo=TRUE)
source('~/Documents/R/rNWIS/R/getMetabSites.R', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
state.list=NA
get.site.matches(state.list,n.param)
get.site.data <- function(site.url){
siteFile <- tryCatch({
siteFile <- read.delim(
site.url,
header = TRUE,
quote="\"",
sep='\t',
colClasses=c('character'),
fill = TRUE,
comment.char="#")
siteFile <- siteFile[-1,]
# assumes rdp format, and single row of headers
}, warning = function(war) {
print(paste("MY_WARNING:  ",war))
# warning handler picks up where error was generated
return(NA)
}, error = function(err) {
print(paste("MY_ERROR:  ",err))
return(NA)
}
)
return(siteFile[-1,]) # get rid of top header
}
get.site.data("http://waterservices.usgs.gov/nwis/site/?format=rdb&stateCd=AS&parameterCd=00010&hasDataTypeCd=iv")
siteFile <- read.delim(
site.url,
header = TRUE,
quote="\"",
sep='\t',
colClasses=c('character'),
fill = TRUE,
comment.char="#")
site.url = "http://waterservices.usgs.gov/nwis/site/?format=rdb&stateCd=AS&parameterCd=00010&hasDataTypeCd=iv"
siteFile <- read.delim(
site.url,
header = TRUE,
quote="\"",
sep='\t',
colClasses=c('character'),
fill = TRUE,
comment.char="#")
get.site.data <- function(site.url){
siteFile <- tryCatch({
siteFile <- read.delim(
site.url,
header = TRUE,
quote="\"",
sep='\t',
colClasses=c('character'),
fill = TRUE,
comment.char="#")
siteFile <- siteFile[-1,]
# assumes rdp format, and single row of headers
}, warning = function(war) {
print(paste("MY_WARNING:  ",war))
# warning handler picks up where error was generated
siteFile <- c(NA,NA)
return(NA)
}, error = function(err) {
print(paste("MY_ERROR:  ",err))
return(NA)
}
)
get.site.data("http://waterservices.usgs.gov/nwis/site/?format=rdb&stateCd=AS&parameterCd=00010&hasDataTypeCd=iv")
get.site.data("http://waterservices.usgs.gov/nwis/site/?format=rdb&stateCd=AS&parameterCd=00010&hasDataTypeCd=iv")
get.site.data("http://waterservices.usgs.gov/nwis/site/?format=rdb&stateCd=AS&parameterCd=00010&hasDataTypeCd=iv")
get.site.data <- function(site.url){
siteFile <- tryCatch({
siteFile <- read.delim(
site.url,
header = TRUE,
quote="\"",
sep='\t',
colClasses=c('character'),
fill = TRUE,
comment.char="#")
siteFile <- siteFile[-1,]
# assumes rdp format, and single row of headers
}, warning = function(war) {
print(paste("MY_WARNING:  ",war))
# warning handler picks up where error was generated
siteFile <- c(NA,NA)
return(NA)
}, error = function(err) {
print(paste("MY_ERROR:  ",err))
return(NA)
}
)
return(siteFile[-1,]) # get rid of top header
}
get.site.data("http://waterservices.usgs.gov/nwis/site/?format=rdb&stateCd=AS&parameterCd=00010&hasDataTypeCd=iv")
dog = get.site.data("http://waterservices.usgs.gov/nwis/site/?format=rdb&stateCd=AS&parameterCd=00010&hasDataTypeCd=iv")
dog
get.site.data <- function(site.url){
siteFile <- tryCatch({
siteFile <- read.delim(
site.url,
header = TRUE,
quote="\"",
sep='\t',
colClasses=c('character'),
fill = TRUE,
comment.char="#")
siteFile <- siteFile[-1,]
# assumes rdp format, and single row of headers
}, warning = function(war) {
print(paste("MY_WARNING:  ",war))
# warning handler picks up where error was generated
siteFile <- c(NA,NA)
return(NA)
}, error = function(err) {
print(paste("MY_ERROR:  ",err))
return(NA)
}
)
return(siteFile) # get rid of top header
}
dog = get.site.data("http://waterservices.usgs.gov/nwis/site/?format=rdb&stateCd=AS&parameterCd=00010&hasDataTypeCd=iv")
dog
source('~/Documents/R/rNWIS/R/getMetabSites.R', echo=TRUE)
state.list
source('~/Documents/R/rNWIS/R/getMetabSites.R', echo=TRUE)
source('~/Documents/R/rNWIS/R/getMetabSites.R', echo=TRUE)
source('~/Documents/R/rNWIS/R/getMetabSites.R', echo=TRUE)
warnings()
source('~/Documents/R/rNWIS/R/getMetabSites.R', echo=TRUE)
source('~/Documents/R/rNWIS/R/getMetabSites.R', echo=TRUE)
source('~/Documents/R/rNWIS/R/getMetabSites.R', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
time.limit
warnings()
write.table(x=time.limit,file='NWIS_metabolism',quote=FALSE,sep='\t',row.names=FALSE,col.names=TRUE)
write.table(x=time.limit,file='NWIS_metabolism.tsv',quote=FALSE,sep='\t',row.names=FALSE,col.names=TRUE)
rep("sd",4)
source('~/Documents/R/rNWIS/R/getMetabSites.R', echo=TRUE)
warnings()
source('~/Documents/R/rNWIS/R/getMetabSites.R', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/Documents/R/rNWIS/R/getMetabSites.R', echo=TRUE)
as.Date("2014-01-23")-as.Date("2013-09-02")
source('~/Documents/R/rNWIS/R/getMetabSites.R', echo=TRUE)
source('~/Documents/R/rNWIS/R/getMetabSites.R', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
?dataRetrieval
library(ncdf4)
?nc_open
nc = nc_open(filename='/Users/jread/Downloads/CA_PATMOSX_NOAA_0130AM_1982.nc')
nc
CA<-ncatt_get(nc=nc, varid="a_CA")
CA
CA<-ncvar_get(nc=nc, varid="a_CA")
dim(CA)
plot(CA[1,1,:])
plot(CA[1,1,])
plot(CA[180,120,])
contour(CA[,,1])
contour(CA[,,2])
contour(CA[,,3])
contour(CA[,,4])
nc
ncatt_get(nc,varid="longitude")
ncatt_get(nc,varid="latitude")
nvar_get(nc,varid="latitude")
ncvar_get(nc,varid="latitude")
setwd("~/Documents/R/GLTC-R/R")
master	<-	read.csv("/Users/jread/Documents/R/GLTC-R/data/Master_2014-01-11.csv")
lake.names	<-	master[1,-c(1,2)]
lake.lat	<-	master[7,-c(1,2)]
lake.lon	<-	master[8,-c(1,2)]
names(master)
master[1,2]
master	<-	read.csv("/Users/jread/Documents/R/GLTC-R/data/Master_2014-01-11.csv",header=TRUE)
lake.names	<-	master[1,-c(1,2)]
lake.lat	<-	master[7,-c(1,2)]
lake.lon	<-	master[8,-c(1,2)]
names(master)
master[1,2]
master[1,]
master[6,]
as.numeric(master[6,])
lake.lat[1]
unlist(lake.lat[1])
lake.lat[[1]
]
as.numeric(lake.lat[[1]])
master	<-	read.csv("/Users/jread/Documents/R/GLTC-R/data/Master_names_lat_lon.csv",header=TRUE)
lake.names	<-	master[1,-c(1,2)]
master	<-	read.csv("/Users/jread/Documents/R/GLTC-R/data/Master_names_lat_lon.csv",header=TRUE)
lake.names	<-	master[1,-c(1,2)]
master	<-	read.csv("/Users/jread/Documents/R/GLTC-R/data/Master_names_lat_lon.csv",header=TRUE,fill=TRUE)
lake.names	<-	master[1,-c(1,2)]
master	<-	read.csv("/Users/jread/Documents/R/GLTC-R/data/Master_names_lat_lon.csv",header=TRUE,fill=TRUE)
lake.names	<-	master[1,-c(1,2)]
master	<-	read.table("/Users/jread/Documents/R/GLTC-R/data/Master_names_lat_lon.txt",header=TRUE,sep='\t')
lake.names	<-	master[1,-c(1,2)]
master	<-	read.table("/Users/jread/Documents/R/GLTC-R/data/Master_names_lat_lon.txt",header=TRUE,sep='\t')
lake.names	<-	master[1,-c(1,2)]
lake.names
master	<-	read.table("/Users/jread/Documents/R/GLTC-R/data/Master_names_lat_lon.txt",header=TRUE,sep='\t')
lake.names	<-	names(master)
lake.lat	<-	master[[1]]
lake.lon	<-	master[[2]]
lake.names
lake.lon
lake.lat
master[[1]]
master[1,]
master[[1,]]
master[[1,2]]
as.numeric(master[,1])
as.numeric(master[1,])
master	<-	read.table("/Users/jread/Documents/R/GLTC-R/data/Master_names_lat_lon.txt",header=TRUE,sep='\t')
lake.names	<-	names(master)
lake.lat	<-	as.numeric(master[1,])
lake.lon	<-	as.numeric(master[2,])
max(lake.lat)
max(lake.lon)
max(lake.lat)
min(lake.lat)
max(lake.lon)
min(lake.lon)
getJAS_CC	<-	function(lat,long,year){
require(ncdf4)
mm.idx	<-	c(7,8,9)
data.dir	<-	"/Users/jread/Documents/R/GLTC-R/data/Cloud_cover_PATMOSX/"
nc	<-	nc_open(filename=paste(data.dir,'CA_PATMOSX_NOAA_0130PM_',as.character(year),'.nc',sep=''))
lat.vals	<-	ncvar_get(nc,varid="latitude")
lon.vals	<-	ncvar_get(nc,varid="longitude")
lat.i	<-	which.min(abs(lat.vals-lat))[1]
lon.i	<-	which.min(abs(lon.vals-long))[1]
CA	<-	ncvar_get(nc=nc, varid="a_CA",start=c(lon.i,lat.i,mm.idx[1]),count=c(1,1,length(mm.idx)))
return(mean(CA))
}
master	<-	read.table("/Users/jread/Documents/R/GLTC-R/data/Master_names_lat_lon.txt",header=TRUE,sep='\t')
lake.names	<-	names(master)
lake.lat	<-	as.numeric(master[1,])
lake.lon	<-	as.numeric(master[2,])
years = seq(1985,2009)
CC = vector(length=length(years)
for (i in 1:length(years)){
CC[i] = getJAS_CC(lake.lat[1],lake.lon[1],years[i])
}
plot(years,CC,pch=3)
CC = vector(length=length(years)
for (i in 1:length(years)){
CC[i] = getJAS_CC(lake.lat[1],lake.lon[1],years[i])
}
seq(1985,2009)
for (i in 1:length(years)){
CC[i] = getJAS_CC(lake.lat[1],lake.lon[1],years[i])
}
getJAS_CC	<-	function(lat,long,year){
require(ncdf4)
mm.idx	<-	c(7,8,9)
data.dir	<-	"/Users/jread/Documents/R/GLTC-R/data/Cloud_cover_PATMOSX/"
nc	<-	nc_open(filename=paste(data.dir,'CA_PATMOSX_NOAA_0130PM_',as.character(year),'.nc',sep=''))
lat.vals	<-	ncvar_get(nc,varid="latitude")
lon.vals	<-	ncvar_get(nc,varid="longitude")
lat.i	<-	which.min(abs(lat.vals-lat))[1]
lon.i	<-	which.min(abs(lon.vals-long))[1]
CA	<-	ncvar_get(nc=nc, varid="a_CA",start=c(lon.i,lat.i,mm.idx[1]),count=c(1,1,length(mm.idx)))
return(mean(CA))
}
master	<-	read.table("/Users/jread/Documents/R/GLTC-R/data/Master_names_lat_lon.txt",header=TRUE,sep='\t')
lake.names	<-	names(master)
lake.lat	<-	as.numeric(master[1,])
lake.lon	<-	as.numeric(master[2,])
years = seq(1985,2009)
CC = vector(length=length(years)
for (i in 1:length(years)){
CC[i] = getJAS_CC(lake.lat[1],lake.lon[1],years[i])
}
plot(years,CC,pch=3)
getJAS_CC	<-	function(lat,long,year){
require(ncdf4)
mm.idx	<-	c(7,8,9)
data.dir	<-	"/Users/jread/Documents/R/GLTC-R/data/Cloud_cover_PATMOSX/"
nc	<-	nc_open(filename=paste(data.dir,'CA_PATMOSX_NOAA_0130PM_',as.character(year),'.nc',sep=''))
lat.vals	<-	ncvar_get(nc,varid="latitude")
lon.vals	<-	ncvar_get(nc,varid="longitude")
lat.i	<-	which.min(abs(lat.vals-lat))[1]
lon.i	<-	which.min(abs(lon.vals-long))[1]
CA	<-	ncvar_get(nc=nc, varid="a_CA",start=c(lon.i,lat.i,mm.idx[1]),count=c(1,1,length(mm.idx)))
return(mean(CA))
}
master	<-	read.table("/Users/jread/Documents/R/GLTC-R/data/Master_names_lat_lon.txt",header=TRUE,sep='\t')
lake.names	<-	names(master)
lake.lat	<-	as.numeric(master[1,])
lake.lon	<-	as.numeric(master[2,])
years = seq(1985,2009)
CC = vector(length=length(years))
for (i in 1:length(years)){
CC[i] = getJAS_CC(lake.lat[1],lake.lon[1],years[i])
}
plot(years,CC,pch=3)
getJAS_CC	<-	function(lat,long,year){
require(ncdf4)
mm.idx	<-	c(7,8,9)
data.dir	<-	"/Users/jread/Documents/R/GLTC-R/data/Cloud_cover_PATMOSX/"
nc	<-	nc_open(filename=paste(data.dir,'CA_PATMOSX_NOAA_0130PM_',as.character(year),'.nc',sep=''))
lat.vals	<-	ncvar_get(nc,varid="latitude")
lon.vals	<-	ncvar_get(nc,varid="longitude")
lat.i	<-	which.min(abs(lat.vals-lat))[1]
lon.i	<-	which.min(abs(lon.vals-long))[1]
CA	<-	ncvar_get(nc=nc, varid="a_CA",start=c(lon.i,lat.i,mm.idx[1]),count=c(1,1,length(mm.idx)))
return(mean(CA))
}
master	<-	read.table("/Users/jread/Documents/R/GLTC-R/data/Master_names_lat_lon.txt",header=TRUE,sep='\t')
lake.names	<-	names(master)
lake.lat	<-	as.numeric(master[1,])
lake.lon	<-	as.numeric(master[2,])
years = seq(1985,2009)
CC = vector(length=length(years))
for (i in 1:length(years)){
CC[i] = getJAS_CC(lake.lat[2],lake.lon[2],years[i])
}
plot(years,CC,pch=3)
getJAS_CC	<-	function(lat,long,year){
require(ncdf4)
mm.idx	<-	c(7,8,9)
data.dir	<-	"/Users/jread/Documents/R/GLTC-R/data/Cloud_cover_PATMOSX/"
nc	<-	nc_open(filename=paste(data.dir,'CA_PATMOSX_NOAA_0130PM_',as.character(year),'.nc',sep=''))
lat.vals	<-	ncvar_get(nc,varid="latitude")
lon.vals	<-	ncvar_get(nc,varid="longitude")
lat.i	<-	which.min(abs(lat.vals-lat))[1]
lon.i	<-	which.min(abs(lon.vals-long))[1]
CA	<-	ncvar_get(nc=nc, varid="a_CA",start=c(lon.i,lat.i,mm.idx[1]),count=c(1,1,length(mm.idx)))
return(mean(CA))
}
master	<-	read.table("/Users/jread/Documents/R/GLTC-R/data/Master_names_lat_lon.txt",header=TRUE,sep='\t')
lake.names	<-	names(master)
lake.lat	<-	as.numeric(master[1,])
lake.lon	<-	as.numeric(master[2,])
years = seq(1985,2009)
CC = vector(length=length(years))
for (i in 1:length(years)){
CC[i] = getJAS_CC(lake.lat[3],lake.lon[3],years[i])
}
plot(years,CC,pch=3)
source('~/.active-rstudio-document', echo=TRUE)
source('~/Documents/R/GLTC-R/R/getJAS_CC.R', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
lake.names[9]
source('~/.active-rstudio-document', echo=TRUE)
lake.names[26]
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
lake.names[34]
which(lake.names=="Kangaroo.Creek.Reservoir")
source('~/.active-rstudio-document', echo=TRUE)
which(lake.names=="Waterfall.Gully")
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
which(lake.names=="Superior.B45006")
source('~/.active-rstudio-document', echo=TRUE)
which(lake.names=="NTL_Crystal")
which(lake.names=="Crystal")
lake.lat[79]
lake.lon[79]
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
